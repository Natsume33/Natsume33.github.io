---
layout: post
title: 简单通用爬虫
date: 2018-07-21 14:52:20 +0300
description: 爬着玩 # Add post description (optional)
img: Bing_1280/95.jpg # Add image post (optional)
fig-caption: # Add figcaption (optional)
tags: [爬虫,Python]
---

简单爬取文本插入数据库 传递网址链接和正则即可

```python
import re
from urllib.request import urlopen,Request
import sqlite3

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'
}

# 数据库操作
class DBManager(object):
    con = None
    cursor = None
    # 定义类方法
    @classmethod
    # 链接数据库并创建表Table  通过参数fieldItems获取字段的数量
    def createDBAndTable(cls,fieldItems,tableName):
        cls.con = sqlite3.connect('DB_all')
        cls.cursor = cls.con.cursor()
        # 拼接游标需要执行的命令
        command = 'create table if not exists {}('.format(tableName)
        tail = ''
        # 字段名为info1-info...
        for fieldItem in range(1,fieldItems+1):
            if fieldItem !=fieldItems:
                tail += 'info{} text,'.format(fieldItem)
            else:
                tail += 'info{} text'.format(fieldItem)
        command +=tail+')'
        # print(command)
        # 创建表
        cls.cursor.execute('{}'.format(command))
    @classmethod
    def closeDB(cls):
        cls.cursor.close()
        cls.con.close()

    @classmethod
    # 添加数据到数据库
    def insertIntoDB(cls,data,tableName):
        # 获取数据元素个数
        length = len(data)
        cls.con = sqlite3.connect('DB_all')
        cls.cursor = cls.con.cursor()
        # 拼接命令
        command = 'insert into {} VALUES ('.format(tableName)
        for i in range(length):
            if i !=length-1:
                command += '"{}",'.format(data[i])
            else:
                command += '"{}")'.format(data[i])

        cls.cursor.execute('{}'.format(command))
        cls.con.commit()


class Spider(object):

    def __init__(self):
        # 实例化对象作为属性 用于操作数据库
        self.dbOpertion = DBManager()
        self.tableName = ''
    #  通过url获取响应的数据code 以及表名tableName
    def getCodeFromUrl(self,url):
        # pattern = re.compile(r'https://www.(.*?).c.*?')
        # self.tableName = pattern.findall(url)[0]
        self.tableName = url.split('.')[1]

        request = Request(url,headers=headers)
        response = urlopen(request)
        try:
            code = response.read().decode()
        except Exception as e:
            print('获取失败')
            return None
        else:
            return code
    # 通过响应的数据code和正则获取目标信息info并返回
    def getInfoAndItemFromCode(self,code,zhengze):
        pattern = re.compile(r'{}'.format(zhengze),re.S)
        info = pattern.findall(code)
        print(info)
        return info
        # if info:
        #     fieldItems = len(info[0])
        #     self.dbOpertion.createDBAndTable(fieldItems,self.tableName)
        #     for index in info:
        #             self.dbOpertion.insertIntoDB(index,self.tableName)
        #     return info,fieldItems
    # 通过返回的info插入数据
    def insertDBFromInfo(self,info):
        # 获取每个元组的长度
        fieldItems = len(info[0])
        self.dbOpertion.createDBAndTable(fieldItems,self.tableName)
        for index in info:
                self.dbOpertion.insertIntoDB(index,self.tableName)
        self.dbOpertion.closeDB()
        return info


patternDict = {
    'https://www.jd.com/allSort.aspx':'<div.*?<dt>.*?<a.*?>(.*?)</a>.*?<a.*?>(.*?)</a>',
    'https://www.qiushibaike.com/hot/page/1':'<div class="author clearfix">.*?<h2>(.*?)</h2>.*?<div class="articleGender.*?Icon">(.*?)</div>.*?<div class="content">.*?<span>(.*?)</span>.*?<span class="stats-vote">.*?<i class="number">(.*?)</i>.*?<span class="stats-comments">.*?<i class="number">(.*?)</i>',
    'http://www.xiaomi.cn/':'<li onclick="_hmt.push.*?<a.*?alt="(.*?)".*?>.*?<p>.*?"(.*?)".*?</p>'
}

spider = Spider()
for u,p in patternDict.items():
    pattern = p
    code = spider.getCodeFromUrl(u)
    info= spider.getInfoAndItemFromCode(code,pattern)
    spider.insertDBFromInfo(info)
	
```


> 更:2018-07-23
>> 数据未进行处理
>> 返回数据没有list化处理 无法判断字符串
>> 需按如下修改getInfoAndItemFromCode()方法返回值,如此,获取一条内容时才能正确处理

```python
        if type(info[0]) == str:
            new_info  = []
            
            for var in info:
                var_list = []
                var_list.append(var)
            new_info.append(var_list)
            return new_info
        else:
            return info 
```

> new: 非list化,对返回值进行判断和去除无用信息

```python
from urllib.request import Request,urlopen
import re,sqlite3


class DBManager(object):
    con = sqlite3.connect('okDB')
    cursor = con.cursor()
    isOneInfo = True
    # dbData = None
    @classmethod
    def createTable(cls,info):
        if cls.isOneInfo ==True:
            cls.cursor.execute('create table if not exists spiderTable(value text)')
            cls.con.commit()
        else:
            sqlStr = 'create table if not exists spiderTable('
            for index,value in enumerate(info):
                sqlStr +='value' + str(index) + ' text,'
            sqlStr = sqlStr[0:-1]
            sqlStr += ')'
            cls.cursor.execute(sqlStr)
            cls.con.commit()
            # print(sqlStr)
    @classmethod
    def insert_into(cls,info):
        if cls.isOneInfo ==True:
            cls.cursor.execute('insert into spiderTable VALUES "{}" '.format(info))
            cls.con.commit()
        else:
            # 多条数据拼接
            sqlStr = 'insert into spiderTable('
            key = ''
            values = ' values('
            for index,value in enumerate(info):
                key += 'value' + str(index) +' ,'
                values +='"' + info[index] +  '"' +' ,'
            key = key[0:-1]
            key += ')'

            values = values[0:-1]
            values +=')'
            # print(key)
            # print(value)
            sqlStr += key + values
            print(sqlStr)
            cls.cursor.execute(sqlStr)
            cls.con.commit()
class DataManager(object):
    # 根据源码获取指定的内容
    @classmethod
    def get_info_with_code(cls,code,pattern):
        # print(code)
        pattern = re.compile(r'{}'.format(pattern),re.S)
        result = pattern.findall(code)
        print(result)

        return result
    @classmethod
    def change_data_with(cls,old_data):
        # 如果获取的时一条数据,那么这条数据类型是字符串,会被放入到列表中
        # 如果获取的是多条数据,那么每条数据都是元组,也会被放入列表中
        space = re.compile(r'\s', re.S)
        element = re.compile(r'<.*?>', re.S)
        if type(old_data) == str:
            old_data = old_data.strip('\n')
            old_data = re.sub(space,'',old_data)
            old_data = re.sub(element,'',old_data)
            DBManager.isOneInfo = True
            return old_data
        else:
            list = []
            for content in old_data:
                print(content)
                content = content.strip('\n')
                content = space.sub('',content)
                content = element.sub('',content)
                list.append(content)
            # print(list)
            DBManager.isOneInfo = False
            return list
class Spider(object):
    def __init__(self,base_url,pattern):
        self.base_url = base_url
        self.pattern = pattern
        self.headers = headers = {
            "User-Agent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'
        }
    def load_url(self):
        url = self.base_url+'1'
        request = Request(url,headers=self.headers)
        response = urlopen(request)
        try:
            code = response.read().decode()
        except Exception as e:
            print('请求首页出错',e)
        else:
            # print(code)
            result_list = DataManager.get_info_with_code(code,self.pattern)
            for value in result_list:
                # 字符串 或者 元组
                newData = DataManager.change_data_with(value)
                # 创建数据表
                DBManager.createTable(newData)
                # 插入数据
                DBManager.insert_into(newData)


spider = Spider('https://www.qiushibaike.com/hot/page/','<div class="author clearfix">.*?<h2>(.*?)</h2>.*?<div class="content">.*?<span>(.*?)</span>')
spider.load_url()

```
